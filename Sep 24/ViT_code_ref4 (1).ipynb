{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"uHIMLUlQxn_s","executionInfo":{"status":"ok","timestamp":1727110558514,"user_tz":-330,"elapsed":2,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["root_dir =\"/content/drive/MyDrive/Zero_Shot_DeepFake_Image_Classification/\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_YdDdtcSxkZw","executionInfo":{"status":"ok","timestamp":1727110566217,"user_tz":-330,"elapsed":6658,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import MultiheadAttention\n","from collections import OrderedDict\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.models import vit_b_16\n","import torch.optim as optim\n","from tqdm import tqdm\n","import os\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import random\n","import torch.fft as fft"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6Va7pDdFVtYf","executionInfo":{"status":"ok","timestamp":1727110566217,"user_tz":-330,"elapsed":3,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["seed = 43\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UKETrgi0xekO","executionInfo":{"status":"ok","timestamp":1727110566218,"user_tz":-330,"elapsed":3,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["dataset_root_dir = root_dir + 'DeepfakeEmpiricalStudy/dataset/'\n","temp_dataset_root_dir = root_dir + 'dataset_small/'\n","train_dir = dataset_root_dir + 'CELEB/train'\n","val_dir = dataset_root_dir + 'CELEB/val'\n","\n","models_root_dir = root_dir + 'DeepfakeEmpiricalStudy_Models/'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9ypW6p62VUBK","executionInfo":{"status":"ok","timestamp":1727110568946,"user_tz":-330,"elapsed":4,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["batch_size = 64\n","num_epochs = 5\n","learning_rate = 1e-4\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"D7Nv9BsQwie5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727110632448,"user_tz":-330,"elapsed":49282,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}},"outputId":"afaf6646-3b9a-4fc5-d38f-0ae9a88c09b3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n","val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=20)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8250,"status":"ok","timestamp":1727110645775,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"},"user_tz":-330},"id":"MK0V69DEValn","outputId":"ad393f66-c130-4902-d889-6e2737db0078"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-377c6b1e8565>:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  vit_weights = torch.load(models_root_dir + 'vit_b_16-c867db91.pth')\n"]}],"source":["class MLPBlock(nn.Module):\n","    def __init__(self, in_features, hidden_features, dropout_prob):\n","        super(MLPBlock, self).__init__()\n","        self.add_module('linear_1', nn.Linear(in_features, hidden_features, bias=True))\n","        self.add_module('1', nn.GELU(approximate='none'))\n","        self.add_module('2', nn.Dropout(dropout_prob))\n","        self.add_module('linear_2', nn.Linear(hidden_features, in_features, bias=True))\n","        self.add_module('4', nn.Dropout(dropout_prob))\n","\n","    def forward(self, x):\n","        for layer in self.children():\n","            x = layer(x)\n","        return x\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, mlp_hidden_dim, dropout_prob):\n","        super(EncoderBlock, self).__init__()\n","        self.ln_1 = nn.LayerNorm(embed_dim, eps=1e-6)\n","        self.self_attention = MultiheadAttention(embed_dim, num_heads, dropout=dropout_prob, batch_first=True)\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.ln_2 = nn.LayerNorm(embed_dim, eps=1e-6)\n","        self.mlp = MLPBlock(embed_dim, mlp_hidden_dim, dropout_prob)\n","\n","    def forward(self, x):\n","        attn_output, _ = self.self_attention(x, x, x)\n","        x = x + self.dropout(attn_output)\n","        x = self.ln_1(x)\n","        mlp_output = self.mlp(x)\n","        x = x + self.dropout(mlp_output)\n","        x = self.ln_2(x)\n","        return x\n","\n","class Encoder(nn.Module):\n","    def __init__(self, embed_dim, num_layers, num_heads, mlp_hidden_dim, dropout_prob, num_patches):\n","        super(Encoder, self).__init__()\n","        self.dropout = nn.Dropout(dropout_prob)\n","\n","        self.pos_embedding = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n","\n","        layers = OrderedDict()\n","        for i in range(num_layers):\n","            layers[f'encoder_layer_{i}'] = EncoderBlock(embed_dim, num_heads, mlp_hidden_dim, dropout_prob)\n","\n","        self.layers = nn.Sequential(layers)\n","        self.ln = nn.LayerNorm(embed_dim, eps=1e-6)\n","\n","    def forward(self, x):\n","        x = x + self.pos_embedding\n","        x = self.dropout(x)\n","        x = self.layers(x)\n","        x = self.ln(x)\n","        return x\n","\n","class VisionTransformer(nn.Module):\n","    def __init__(self, img_size=224, patch_size=16, in_channels=3, num_classes=1000, embed_dim=768, num_layers=12, num_heads=12, mlp_hidden_dim=3072, dropout_prob=0.0):\n","        super(VisionTransformer, self).__init__()\n","        self.patch_size = patch_size\n","        self.num_patches = (img_size // patch_size) ** 2\n","\n","        self.conv_proj = nn.Conv2d(in_channels, embed_dim, kernel_size=(patch_size, patch_size), stride=(patch_size, patch_size))\n","\n","        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n","\n","        self.encoder = Encoder(embed_dim, num_layers, num_heads, mlp_hidden_dim, dropout_prob, self.num_patches)\n","\n","        self.heads = nn.Sequential(OrderedDict([('head', nn.Linear(embed_dim, num_classes))]))\n","\n","    def forward(self, x):\n","\n","        x = self.conv_proj(x)  # Shape [batch_size, embed_dim, num_patches_height, num_patches_width]\n","        x = x.flatten(2)  # Shape [batch_size, embed_dim, num_patches]\n","        x = x.transpose(1, 2)  # Shape [batch_size, num_patches, embed_dim]\n","\n","        batch_size = x.size(0)\n","        class_token = self.class_token.expand(batch_size, -1, -1)  # Shape [batch_size, 1, embed_dim]\n","        x = torch.cat((class_token, x), dim=1)  # Shape [batch_size, num_patches + 1, embed_dim]\n","\n","        x = self.encoder(x)\n","        x = x[:, 0]\n","        x = self.heads(x)\n","        return x\n","\n","\n","model = VisionTransformer(num_classes=2).to(device)\n","vit_weights = torch.load(models_root_dir + 'vit_b_16-c867db91.pth')\n","model_state_dict = model.state_dict()\n","layers_to_load = list(model_state_dict.keys())[:-2]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1727110648137,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"},"user_tz":-330},"id":"WermizqTpPV8","outputId":"870c608b-0c9a-425e-beca-84cbcb69f515"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_IncompatibleKeys(missing_keys=['heads.head.weight', 'heads.head.bias'], unexpected_keys=[])"]},"metadata":{},"execution_count":9}],"source":["filtered_weights = {k: v for k, v in vit_weights.items() if k in layers_to_load}\n","filtered_weights = {k: v for k, v in filtered_weights.items() if k in model_state_dict}\n","model.load_state_dict(filtered_weights, strict=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kt6x7RVQpROp","executionInfo":{"status":"ok","timestamp":1727110658978,"user_tz":-330,"elapsed":860,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"aQ4SwYmNVfYP","executionInfo":{"status":"ok","timestamp":1727110666616,"user_tz":-330,"elapsed":859,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["def evaluate_model(model, loader, criterion):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            with torch.cuda.amp.autocast():  # Enable mixed precision\n","                outputs = model(inputs)\n","\n","            # Get predicted classes\n","            _, predicted = torch.max(outputs, 1)\n","\n","            # Update total and correct counts\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # Collect predictions and labels\n","            all_preds.append(predicted)\n","            all_labels.append(labels)\n","\n","    # Concatenate all predictions and labels at once\n","    all_preds = torch.cat(all_preds).cpu().numpy()\n","    all_labels = torch.cat(all_labels).cpu().numpy()\n","\n","    return correct / total, all_labels, all_preds\n","\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n","    model.train()\n","    best_acc = 0.0\n","    scaler = torch.cuda.amp.GradScaler()  # Initialize GradScaler for mixed precision\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for inputs, labels in tqdm(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()  # Zero the gradients\n","            with torch.cuda.amp.autocast():  # Enable mixed precision\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","            scaler.scale(loss).backward()  # Scale the loss for backpropagation\n","            scaler.step(optimizer)  # Update the optimizer\n","            scaler.update()  # Update the scaler\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        train_acc = correct / total\n","        val_acc = evaluate_model(model, val_loader, criterion)[0]\n","\n","        print(f\"Epoch {epoch+1}, Loss: {running_loss/total:.4f}, Train Accuracy: {train_acc:.4f}, Val Accuracy: {val_acc:.4f}\")\n","\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            torch.save(model.state_dict(), models_root_dir + 'best_trained_model.pth')\n","            print('Model saved!')\n","\n","    print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1108110,"status":"ok","timestamp":1727111777316,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"},"user_tz":-330},"id":"7lSeHcxNACd9","outputId":"b38c9184-3a62-40d3-d002-a6eda513ba80"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-894632968d13>:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()  # Initialize GradScaler for mixed precision\n","  0%|          | 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","<ipython-input-12-894632968d13>:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # Enable mixed precision\n","100%|██████████| 250/250 [09:22<00:00,  2.25s/it]\n","<ipython-input-12-894632968d13>:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # Enable mixed precision\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.7052, Train Accuracy: 0.5000, Val Accuracy: 0.5000\n","Model saved!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [01:42<00:00,  2.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Loss: 0.6951, Train Accuracy: 0.4985, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [01:42<00:00,  2.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Loss: 0.6956, Train Accuracy: 0.5085, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [01:42<00:00,  2.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Loss: 0.6953, Train Accuracy: 0.5086, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [01:42<00:00,  2.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Loss: 0.6952, Train Accuracy: 0.5032, Val Accuracy: 0.5000\n","Training complete. Best validation accuracy: 0.5000\n"]}],"source":["train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"OBg1hdZ6q29G"},"source":["# **Testing**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"q1lo3aSmq6g-","executionInfo":{"status":"ok","timestamp":1727111828520,"user_tz":-330,"elapsed":686,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["test_dirs = [dataset_root_dir + 'FS/test', dataset_root_dir + 'NT/test']"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ug5qQ0Brq6g_","executionInfo":{"status":"ok","timestamp":1727111831839,"user_tz":-330,"elapsed":4,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}}},"outputs":[],"source":["def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n","    plt.title(title)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DBlZOWwAq6g_","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"error","timestamp":1727111863643,"user_tz":-330,"elapsed":24691,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"}},"outputId":"4bb94d1a-7372-411c-c5d0-39e694f8edfa"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-6c41533880cc>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(models_root_dir + 'best_trained_model.pth'))\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-6c41533880cc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy for {test_dir}: {test_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-894632968d13>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, loader, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Enable mixed precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3375\u001b[0;31m def open(\n\u001b[0m\u001b[1;32m   3376\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrOrBytesPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m     \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.load_state_dict(torch.load(models_root_dir + 'best_trained_model.pth'))\n","\n","all_labels_combined = []\n","all_preds_combined = []\n","\n","for test_dir in test_dirs:\n","    test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    test_acc, all_labels, all_preds = evaluate_model(model, test_loader, criterion)\n","    print(f\"Test Accuracy for {test_dir}: {test_acc:.4f}\")\n","\n","    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n","    plot_confusion_matrix(cm, classes=['real', 'fake'], title=f'Confusion Matrix for {test_dir}')\n","\n","    all_labels_combined.extend(all_labels)\n","    all_preds_combined.extend(all_preds)\n","\n","cm_combined = confusion_matrix(all_labels_combined, all_preds_combined, labels=[0, 1])\n","print(f\"Average Accuracy: {np.mean([evaluate_model(model, DataLoader(datasets.ImageFolder(test_dir, transform=transform), batch_size=batch_size, shuffle=False), criterion)[0] for test_dir in test_dirs]):.4f}\")\n","plot_confusion_matrix(cm_combined, classes=['real', 'fake'], title='Combined Confusion Matrix')"]},{"cell_type":"markdown","metadata":{"id":"Qs0FbV6wneA0"},"source":["# **Testing on Unseen datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDTuyE9pnfiv"},"outputs":[],"source":["test_dirs = [temp_dataset_root_dir + 'CELEB/val', temp_dataset_root_dir + 'DF/test', temp_dataset_root_dir + 'DFD/test', \\\n","             temp_dataset_root_dir + 'F2F/val' ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXMNgFIZnx5G"},"outputs":[],"source":["def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n","    plt.title(title)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOkLFUQZnuNS"},"outputs":[],"source":["model.load_state_dict(torch.load(models_root_dir + 'best_trained_model.pth'))\n","\n","all_labels_combined = []\n","all_preds_combined = []\n","\n","for test_dir in test_dirs:\n","    test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    test_acc, all_labels, all_preds = evaluate_model(model, test_loader, criterion)\n","    print(f\"Test Accuracy for {test_dir}: {test_acc:.4f}\")\n","\n","    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n","    plot_confusion_matrix(cm, classes=['real', 'fake'], title=f'Confusion Matrix for {test_dir}')\n","\n","    all_labels_combined.extend(all_labels)\n","    all_preds_combined.extend(all_preds)\n","\n","cm_combined = confusion_matrix(all_labels_combined, all_preds_combined, labels=[0, 1])\n","print(f\"Average Accuracy: {np.mean([evaluate_model(model, DataLoader(datasets.ImageFolder(test_dir, transform=transform), batch_size=batch_size, shuffle=False), criterion)[0] for test_dir in test_dirs]):.4f}\")\n","plot_confusion_matrix(cm_combined, classes=['real', 'fake'], title='Combined Confusion Matrix')"]},{"cell_type":"markdown","metadata":{"id":"3DaSUO7WuDTI"},"source":["# **Explainability**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJkXhK5OuRna"},"outputs":[],"source":["!pip install captum --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1727026337270,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"},"user_tz":-330},"id":"xX9nhPmHwxSN","outputId":"23f39a5a-4af1-491d-e4a1-7b2cf6e3f1d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-559b6e824e13>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(models_root_dir + 'best_trained_model.pth'))\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(models_root_dir + 'best_trained_model.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"11leg6OVuiIsdUw1xPFRyfZUSxuqXu7qO"},"executionInfo":{"elapsed":29958,"status":"error","timestamp":1727026372538,"user":{"displayName":"SWATHI R","userId":"01338665695010248846"},"user_tz":-330},"id":"gJ6r12XLuMTh","outputId":"c48d5895-e1a8-4bd9-a1d7-e9b2de5918ad"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from captum.attr import LayerGradCam, LayerAttribution\n","import cv2\n","\n","def visualize_cam_on_image(image, cam_output):\n","    cam_output = cam_output.cpu().detach().numpy()\n","    cam_output = (cam_output - cam_output.min()) / (cam_output.max() - cam_output.min())  # Normalize\n","\n","    cam_output = cv2.resize(cam_output, (image.shape[1], image.shape[2]))  # Reshape to input size\n","    heatmap = cv2.applyColorMap(np.uint8(255 * cam_output), cv2.COLORMAP_JET)\n","    heatmap = np.float32(heatmap) / 255\n","    cam_image = heatmap + np.float32(image.permute(1, 2, 0).cpu().detach().numpy())\n","    cam_image = cam_image / np.max(cam_image)\n","\n","    return cam_image\n","\n","def generate_grad_cam(model, input_tensor, target_class=None):\n","    grad_cam = LayerGradCam(model, model.encoder.layers[-1])\n","    cam_output = grad_cam.attribute(input_tensor, target=target_class)\n","\n","    return cam_output\n","\n","test_dir = temp_dataset_root_dir + 'CELEB/val'\n","test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Generate Grad-CAM output for a batch of images\n","model.eval()\n","inputs, _ = next(iter(test_loader))  # Get a batch of validation images\n","inputs = inputs.to(device)\n","\n","cam_output = generate_grad_cam(model, inputs, target_class = 0)\n","for i in range(inputs.size(0)):\n","    print(inputs[i].shape)\n","    cam_image = visualize_cam_on_image(inputs[i], cam_output[i])\n","    plt.imshow(cam_image)\n","    plt.title(f\"Image {i+1}\")\n","    plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"mount_file_id":"1TcsE9qTzQMfRmjTMThJewqF2e5DbP5gP","authorship_tag":"ABX9TyP0xiwm9kuU4uy2O+0OgSk2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}